# I-JEPA

<head>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
</head>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" src="https://www.youtube.com/embed/7NE0NH-PfkA" frameborder="0" allowfullscreen></iframe>
</div>


## Acknowledgment:
Thanks to the authors for making their code available. If I had any misunderstandings while reading the paper, I had to check the code to confirm it.

## References:
```bibtex
@InProceedings{chen2020simple,
  title    = {A Simple Framework for Contrastive Learning of Visual Representations},
  author   = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle= {Proceedings of the 37th International Conference on Machine Learning},
  pages    = {1597--1607},
  year     = {2020},
  volume   = {119},
  series   = {Proceedings of Machine Learning Research},
  month    = {13--18 Jul},
  publisher= {PMLR},
  url      = {https://proceedings.mlr.press/v119/chen20j.html},
}
```

```console
INFO:root:Epoch 1
itr: 0
unsupervised_loader length 8
imgs.shape torch.Size([128, 3, 224, 224])
masks_enc[0].shape torch.Size([128, 57])
masks_enc length 1
masks_pred[0].shape torch.Size([128, 42])
masks_pred length 4
/Users/mashaanalshammari/Downloads/ijepa/src/train.py:325: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=use_bfloat16):
/opt/miniconda3/envs/ijepa/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
inside forward_target
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 256, 768])
x.shape after blocks:  torch.Size([128, 256, 768])
---------------encoder end-------------------
inside forward_context
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 57, 768])
x.shape after blocks:  torch.Size([128, 57, 768])
---------------encoder end-------------------
---------------predictor start---------------
x.shape: torch.Size([128, 57, 768])
masks_x[0].shape torch.Size([128, 57])
masks_x length 1
masks[0].shape torch.Size([128, 42])
masks length 4
Batch Size: 128
x.shape after predictor_embed: torch.Size([128, 57, 384])
x_pos_embed.shape: torch.Size([128, 256, 384])
x.shape after adding positional embedding: torch.Size([128, 57, 384])
N_ctxt: 57
pos_embs.shape: torch.Size([512, 42, 384])
pred_tokens.shape: torch.Size([512, 42, 384])
x.shape after concat mask tokens: torch.Size([512, 99, 384])
x.shape after predictor_blocks: torch.Size([512, 99, 384])
x.shape after pulling mask tokens: torch.Size([512, 42, 384])
x.shape after predictor_proj: torch.Size([512, 42, 768])
---------------predictor end-----------------
INFO:root:[1,     0] loss: 0.468 masks: 57.0 42.0 [wd: 4.00e-02] [lr: 2.03e-04] [mem: 0.00e+00] (-1.0 ms)
INFO:root:[1,     0] grad_stats: [2.91e-02 1.51e-02] (1.46e-02, 3.33e-02)
itr: 1
```

---

```console
INFO:root:Epoch 1
itr: 0
unsupervised_loader length 8
imgs.shape torch.Size([128, 3, 224, 224])
masks_enc[0].shape torch.Size([128, 57])
masks_enc length 1
masks_pred[0].shape torch.Size([128, 42])
masks_pred length 4
inside forward_target
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 256, 768])
x.shape after blocks:  torch.Size([128, 256, 768])
---------------encoder end-------------------
inside forward_context
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 57, 768])
x.shape after blocks:  torch.Size([128, 57, 768])
---------------encoder end-------------------
---------------predictor start---------------
x.shape: torch.Size([128, 57, 768])
masks_x[0].shape torch.Size([128, 57])
masks_x length 1
masks[0].shape torch.Size([128, 42])
masks length 4
Batch Size: 128
x.shape after predictor_embed: torch.Size([128, 57, 384])
x_pos_embed.shape: torch.Size([128, 256, 384])
x.shape after adding positional embedding: torch.Size([128, 57, 384])
pos_embs.shape: torch.Size([512, 42, 384])
pred_tokens.shape: torch.Size([512, 42, 384])
x.shape after concat mask tokens: torch.Size([512, 99, 384])
x.shape after predictor_blocks: torch.Size([512, 99, 384])
---------------predictor end-----------------
INFO:root:[1,     0] loss: 0.468 masks: 57.0 42.0 [wd: 4.00e-02] [lr: 2.03e-04] [mem: 0.00e+00] (-1.0 ms)
INFO:root:[1,     0] grad_stats: [2.91e-02 1.51e-02] (1.46e-02, 3.33e-02)
itr: 1
unsupervised_loader length 8
imgs.shape torch.Size([128, 3, 224, 224])
masks_enc[0].shape torch.Size([128, 94])
masks_enc length 1
masks_pred[0].shape torch.Size([128, 35])
masks_pred length 4
inside forward_target
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 256, 768])
x.shape after blocks:  torch.Size([128, 256, 768])
---------------encoder end-------------------
inside forward_context
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 94, 768])
x.shape after blocks:  torch.Size([128, 94, 768])
---------------encoder end-------------------
---------------predictor start---------------
x.shape: torch.Size([128, 94, 768])
masks_x[0].shape torch.Size([128, 94])
masks_x length 1
masks[0].shape torch.Size([128, 35])
masks length 4
Batch Size: 128
x.shape after predictor_embed: torch.Size([128, 94, 384])
x_pos_embed.shape: torch.Size([128, 256, 384])
x.shape after adding positional embedding: torch.Size([128, 94, 384])
pos_embs.shape: torch.Size([512, 35, 384])
pred_tokens.shape: torch.Size([512, 35, 384])
x.shape after concat mask tokens: torch.Size([512, 129, 384])
x.shape after predictor_blocks: torch.Size([512, 129, 384])
---------------predictor end-----------------
itr: 2
unsupervised_loader length 8
imgs.shape torch.Size([128, 3, 224, 224])
masks_enc[0].shape torch.Size([128, 61])
masks_enc length 1
masks_pred[0].shape torch.Size([128, 48])
masks_pred length 4
inside forward_target
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 256, 768])
x.shape after blocks:  torch.Size([128, 256, 768])
---------------encoder end-------------------
inside forward_context
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 61, 768])
x.shape after blocks:  torch.Size([128, 61, 768])
---------------encoder end-------------------
---------------predictor start---------------
x.shape: torch.Size([128, 61, 768])
masks_x[0].shape torch.Size([128, 61])
masks_x length 1
masks[0].shape torch.Size([128, 48])
masks length 4
Batch Size: 128
x.shape after predictor_embed: torch.Size([128, 61, 384])
x_pos_embed.shape: torch.Size([128, 256, 384])
x.shape after adding positional embedding: torch.Size([128, 61, 384])
pos_embs.shape: torch.Size([512, 48, 384])
pred_tokens.shape: torch.Size([512, 48, 384])
x.shape after concat mask tokens: torch.Size([512, 109, 384])
x.shape after predictor_blocks: torch.Size([512, 109, 384])
---------------predictor end-----------------
itr: 3
unsupervised_loader length 8
imgs.shape torch.Size([128, 3, 224, 224])
masks_enc[0].shape torch.Size([128, 67])
masks_enc length 1
masks_pred[0].shape torch.Size([128, 42])
masks_pred length 4
inside forward_target
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 256, 768])
x.shape after blocks:  torch.Size([128, 256, 768])
---------------encoder end-------------------
inside forward_context
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 67, 768])
x.shape after blocks:  torch.Size([128, 67, 768])
---------------encoder end-------------------
---------------predictor start---------------
x.shape: torch.Size([128, 67, 768])
masks_x[0].shape torch.Size([128, 67])
masks_x length 1
masks[0].shape torch.Size([128, 42])
masks length 4
Batch Size: 128
x.shape after predictor_embed: torch.Size([128, 67, 384])
x_pos_embed.shape: torch.Size([128, 256, 384])
x.shape after adding positional embedding: torch.Size([128, 67, 384])
pos_embs.shape: torch.Size([512, 42, 384])
pred_tokens.shape: torch.Size([512, 42, 384])
x.shape after concat mask tokens: torch.Size([512, 109, 384])
x.shape after predictor_blocks: torch.Size([512, 109, 384])
---------------predictor end-----------------
itr: 4
unsupervised_loader length 8
imgs.shape torch.Size([128, 3, 224, 224])
masks_enc[0].shape torch.Size([128, 67])
masks_enc length 1
masks_pred[0].shape torch.Size([128, 42])
masks_pred length 4
inside forward_target
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 256, 768])
x.shape after blocks:  torch.Size([128, 256, 768])
---------------encoder end-------------------
inside forward_context
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 67, 768])
x.shape after blocks:  torch.Size([128, 67, 768])
---------------encoder end-------------------
---------------predictor start---------------
x.shape: torch.Size([128, 67, 768])
masks_x[0].shape torch.Size([128, 67])
masks_x length 1
masks[0].shape torch.Size([128, 42])
masks length 4
Batch Size: 128
x.shape after predictor_embed: torch.Size([128, 67, 384])
x_pos_embed.shape: torch.Size([128, 256, 384])
x.shape after adding positional embedding: torch.Size([128, 67, 384])
pos_embs.shape: torch.Size([512, 42, 384])
pred_tokens.shape: torch.Size([512, 42, 384])
x.shape after concat mask tokens: torch.Size([512, 109, 384])
x.shape after predictor_blocks: torch.Size([512, 109, 384])
---------------predictor end-----------------
itr: 5
unsupervised_loader length 8
imgs.shape torch.Size([128, 3, 224, 224])
masks_enc[0].shape torch.Size([128, 75])
masks_enc length 1
masks_pred[0].shape torch.Size([128, 42])
masks_pred length 4
inside forward_target
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 256, 768])
x.shape after blocks:  torch.Size([128, 256, 768])
---------------encoder end-------------------
inside forward_context
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 75, 768])
x.shape after blocks:  torch.Size([128, 75, 768])
---------------encoder end-------------------
---------------predictor start---------------
x.shape: torch.Size([128, 75, 768])
masks_x[0].shape torch.Size([128, 75])
masks_x length 1
masks[0].shape torch.Size([128, 42])
masks length 4
Batch Size: 128
x.shape after predictor_embed: torch.Size([128, 75, 384])
x_pos_embed.shape: torch.Size([128, 256, 384])
x.shape after adding positional embedding: torch.Size([128, 75, 384])
pos_embs.shape: torch.Size([512, 42, 384])
pred_tokens.shape: torch.Size([512, 42, 384])
x.shape after concat mask tokens: torch.Size([512, 117, 384])
x.shape after predictor_blocks: torch.Size([512, 117, 384])
---------------predictor end-----------------
itr: 6
unsupervised_loader length 8
imgs.shape torch.Size([128, 3, 224, 224])
masks_enc[0].shape torch.Size([128, 65])
masks_enc length 1
masks_pred[0].shape torch.Size([128, 48])
masks_pred length 4
inside forward_target
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 256, 768])
x.shape after blocks:  torch.Size([128, 256, 768])
---------------encoder end-------------------
inside forward_context
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 65, 768])
x.shape after blocks:  torch.Size([128, 65, 768])
---------------encoder end-------------------
---------------predictor start---------------
x.shape: torch.Size([128, 65, 768])
masks_x[0].shape torch.Size([128, 65])
masks_x length 1
masks[0].shape torch.Size([128, 48])
masks length 4
Batch Size: 128
x.shape after predictor_embed: torch.Size([128, 65, 384])
x_pos_embed.shape: torch.Size([128, 256, 384])
x.shape after adding positional embedding: torch.Size([128, 65, 384])
pos_embs.shape: torch.Size([512, 48, 384])
pred_tokens.shape: torch.Size([512, 48, 384])
x.shape after concat mask tokens: torch.Size([512, 113, 384])
x.shape after predictor_blocks: torch.Size([512, 113, 384])
---------------predictor end-----------------
itr: 7
unsupervised_loader length 8
imgs.shape torch.Size([128, 3, 224, 224])
masks_enc[0].shape torch.Size([128, 64])
masks_enc length 1
masks_pred[0].shape torch.Size([128, 42])
masks_pred length 4
inside forward_target
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 256, 768])
x.shape after blocks:  torch.Size([128, 256, 768])
---------------encoder end-------------------
inside forward_context
---------------encoder start-----------------
x.shape:  torch.Size([128, 3, 224, 224])
x.shape:  torch.Size([128, 256, 768])
pos_embed.shape:  torch.Size([1, 256, 768])
x.shape after pos_embed:  torch.Size([128, 256, 768])
x.shape after mask:  torch.Size([128, 64, 768])
x.shape after blocks:  torch.Size([128, 64, 768])
---------------encoder end-------------------
---------------predictor start---------------
x.shape: torch.Size([128, 64, 768])
masks_x[0].shape torch.Size([128, 64])
masks_x length 1
masks[0].shape torch.Size([128, 42])
masks length 4
Batch Size: 128
x.shape after predictor_embed: torch.Size([128, 64, 384])
x_pos_embed.shape: torch.Size([128, 256, 384])
x.shape after adding positional embedding: torch.Size([128, 64, 384])
pos_embs.shape: torch.Size([512, 42, 384])
pred_tokens.shape: torch.Size([512, 42, 384])
x.shape after concat mask tokens: torch.Size([512, 106, 384])
x.shape after predictor_blocks: torch.Size([512, 106, 384])
---------------predictor end-----------------
INFO:root:avg. loss 0.328
INFO:root:Epoch 2
itr: 0
```

<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '$$', right: '$$', display: true}, // Display math (e.g., equations on their own line)
        {left: '$', right: '$', display: false},  // Inline math (e.g., within a sentence)
        {left: '\\(', right: '\\)', display: false}, // Another way to write inline math
        {left: '\\[', right: '\\]', display: true}   // Another way to write display math
      ]
    });
  });
</script>

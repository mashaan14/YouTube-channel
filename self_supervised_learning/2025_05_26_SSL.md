# Self-Supervised Learning Review: from SimCLR to DINOv2

<head>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
</head>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" src="https://www.youtube.com/embed/G6c6zk0RhRM" frameborder="0" allowfullscreen></iframe>
</div>

## Acknowledgment:
I borrowed some code from [DINOv2 repository](https://github.com/facebookresearch/dinov2).

## References:
```bibtex
@inproceedings{caron2021emerging,
  title     = {Emerging Properties in Self-Supervised Vision Transformers},
  author    = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle = {Proceedings of the International Conference on Computer Vision (ICCV)},
  year      = {2021}
}
```

![drawings 001](https://github.com/user-attachments/assets/df19cfb5-a591-45a5-9ea9-fe5e131fb50f)

## SimCLR

![drawings-02 001](https://github.com/user-attachments/assets/c9c19cde-0bac-43ba-be8c-dc1508615a18)

---

![drawings 004](https://github.com/user-attachments/assets/be97b241-8429-4f1f-8230-ba1db6aec673)

---

![drawings 005](https://github.com/user-attachments/assets/77304cbd-1369-4a29-b773-43f0c139ea5b)

---

![drawings 006](https://github.com/user-attachments/assets/fa5b86ae-7cc6-43c2-b66d-d5df9227da8a)

## BYOL

![drawings-02 002](https://github.com/user-attachments/assets/2e2e32a7-67e9-4ff1-a795-650273c8e3a6)

## SwAV

SwAV added a layer to cluster the images. Their motivation was to avoid the costly pairwise assignment of positive and negative pairs.

> Comparing cluster assignments allows to contrast different image views while not relying on explicit pairwise feature comparisons.

source: Caron et al., 2020

![drawings-02 003](https://github.com/user-attachments/assets/f38b09c6-1960-4c9f-9757-2b711a5071bc)

---

SwAV uses multi-crop training, where the image is cropped into smaller sizes.

> In this work, we propose multi-crop that uses smaller-sized images to increase the number of views while not increasing the memory or computational requirements during training.

source: Caron et al., 2020

![drawings-01 005](https://github.com/user-attachments/assets/f2d24ab0-0c3c-4a50-88d2-1f735aef8fd4)



<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '$$', right: '$$', display: true}, // Display math (e.g., equations on their own line)
        {left: '$', right: '$', display: false},  // Inline math (e.g., within a sentence)
        {left: '\\(', right: '\\)', display: false}, // Another way to write inline math
        {left: '\\[', right: '\\]', display: true}   // Another way to write display math
      ]
    });
  });
</script>
